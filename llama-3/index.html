<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Llama-3-ELYZA-JP導入 - Kumanekokk Lab</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
        <link href="../css/common.css" rel="stylesheet" />
        <link href="//use.fontawesome.com/releases/v6.2.0/css/all.css" rel="stylesheet" />
        <link href="//fonts.googleapis.com/earlyaccess/notosansjp.css" rel="stylesheet" />
        <link href="//fonts.googleapis.com/css?family=Open+Sans:600,800" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Llama-3-ELYZA-JP\u5c0e\u5165";
        var mkdocs_page_input_path = "llama-3.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Kumanekokk Lab
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Version History</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">生成AI</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="#">共通設定</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../python-dev/">Python導入</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">大規模言語モデル</a>
    <ul class="current">
                <li class="toctree-l2"><a class="reference internal" href="../phi-3-mini/">Phi-3-mini導入</a>
                </li>
                <li class="toctree-l2 current"><a class="reference internal current" href="./">Llama-3-ELYZA-JP導入</a>
    <ul class="current">
    <li class="toctree-l3"><a class="reference internal" href="#_1">概要</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#webui">ローカルで大規模言語モデルを利用するためのWebUI導入</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#1">① 任意の場所からターミナルを開き、下記のコマンドを実行。</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#2-gpu">② インストール途中でGPU選択が表示されるので、利用する環境を選択。</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#3-webhttp1270017860">③ インストールが正常に完了したら、Webブラウザで「http://127.0.0.1:7860」を開く。</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#llama-3-elyza-jp">Llama-3-ELYZA-JPのダウンロードと反映</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#1-modeldownload-model-or-loraelyzallama-3-elyza-jp-8b-ggufget-file-list">① 「Model」タブを開いて「Download model or LoRA」に「elyza/Llama-3-ELYZA-JP-8B-GGUF」と入力し「Get file list」ボタンを押下。</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#2-file-name-for-gguf-modelsllama-3-elyza-jp-8b-q4_k_mggufdownload">② 「File name (for GGUF models)」と書かれたテキストボックスに「Llama-3-ELYZA-JP-8B-q4_k_m.gguf」と入力し「Download」ボタンを押下する。</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#3-model-llama-3-elyza-jp-8b-q4_k_mggufloadsave-settings">③ 画面左上の「Model」選択プルダウン右の更新(ぐるぐる矢印)ボタンを押下し、 プルダウンから「Llama-3-ELYZA-JP-8B-q4_k_m.gguf」を選択した状態で「Load」ボタンと「Save settings」ボタンを押下する。</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#_2">動作確認</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#chatsend-a-messagegenerate">「Chat」タブを開き、画面下の「Send a message」と書かれたテキストボックスに質問などを入力し「Generate」ボタンを押下する。</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#_3">参考サイト</a>
    </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">画像生成モデル</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../stable-diffusion/">Stable-Diffusion導入</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../comfy-ui/">ComfyUI導入</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">動画生成モデル</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../luma-dream-machine/">Luma-Dream-Machine導入</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../runway-gen/">Runway-Gen導入</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">音声合成モデル</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../vall-e-x/">VALL-E-X導入</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../voicebox/">VOICEBOX導入</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">音声認識モデル</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../whisper/">Whisper導入</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">音楽生成モデル</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../stable-audio/">Stable-Audio導入</a>
                </li>
    </ul>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">その他</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../static-gen/">静的サイトジェネレータ</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Kumanekokk Lab</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" alt="Docs"></a> &raquo;</li>
          <li>生成AI &raquo;</li>
          <li>大規模言語モデル &raquo;</li><li>Llama-3-ELYZA-JP導入</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>

          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="llama-3-elyza-jp-20240716">Llama-3-ELYZA-JP導入 (2024/07/16)<a class="headerlink" href="#llama-3-elyza-jp-20240716" title="Permanent link">&para;</a></h1>
<h2 id="_1">概要<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<ul>
<li>AI研究の第一人者である東京大学・松尾豊教授の研究室のメンバーが立ち上げたELYZAが提供する、大規模言語モデル「ELYZA LLM for JP」シリーズの最新モデルとして、Meta社の「Llama 3」をベースとした700億パラメータの「Llama-3-ELYZA-JP-70B」と80億パラメータの「Llama-3-ELYZA-JP-8B」。<ul>
<li>70Bモデルは「GPT-4」「Claude 3 Sonnet」などの商用グローバルモデルを上回る性能を実現。<ul>
<li>チャット形式のデモも用意。高性能な国内製モデルとして、企業向けに提供を予定。</li>
</ul>
</li>
<li>8Bモデルは「GPT-3.5 turbo」を上回る性能を達成し、オープンなモデルのなかでは最高水準の性能を達成。<ul>
<li>研究および商業目的での利用が可能な形式で一般公開。</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr />
<h2 id="webui">ローカルで大規模言語モデルを利用するためのWebUI導入<a class="headerlink" href="#webui" title="Permanent link">&para;</a></h2>
<h3 id="1">① 任意の場所からターミナルを開き、下記のコマンドを実行。<a class="headerlink" href="#1" title="Permanent link">&para;</a></h3>
<pre><code class="language-shell">git clone https://github.com/oobabooga/text-generation-webui.git
cd text-generation-webui
./start_windows.bat
</code></pre>
<ul>
<li>Gitクライアントはあらかじめインストールしておく。</li>
</ul>
<h3 id="2-gpu">② インストール途中でGPU選択が表示されるので、利用する環境を選択。<a class="headerlink" href="#2-gpu" title="Permanent link">&para;</a></h3>
<pre><code class="language-shell">A) NVIDIA
B) AMD (Linux/MacOS only. Requires ROCm SDK 5.6 on Linux)
C) Apple M Series
D) Intel Arc (IPEX)
N) None (I want to run models in CPU mode)
</code></pre>
<ul>
<li>多分上のほうを利用できると高速です。(検証環境は「RTX2060」のため「A」を入力)</li>
</ul>
<h3 id="3-webhttp1270017860">③ インストールが正常に完了したら、Webブラウザで「<a href="http://127.0.0.1:7860">http://127.0.0.1:7860</a>」を開く。<a class="headerlink" href="#3-webhttp1270017860" title="Permanent link">&para;</a></h3>
<ul>
<li>他のソフトがポートを占有している場合、画面に表示されているURLを開く。</li>
</ul>
<hr />
<h2 id="llama-3-elyza-jp">Llama-3-ELYZA-JPのダウンロードと反映<a class="headerlink" href="#llama-3-elyza-jp" title="Permanent link">&para;</a></h2>
<h3 id="1-modeldownload-model-or-loraelyzallama-3-elyza-jp-8b-ggufget-file-list">① 「Model」タブを開いて「Download model or LoRA」に「elyza/Llama-3-ELYZA-JP-8B-GGUF」と入力し「Get file list」ボタンを押下。<a class="headerlink" href="#1-modeldownload-model-or-loraelyzallama-3-elyza-jp-8b-ggufget-file-list" title="Permanent link">&para;</a></h3>
<ul>
<li>成功したら「Hugging Face」に登録されているファイルリストが表示されるする。</li>
</ul>
<h3 id="2-file-name-for-gguf-modelsllama-3-elyza-jp-8b-q4_k_mggufdownload">② 「File name (for GGUF models)」と書かれたテキストボックスに「Llama-3-ELYZA-JP-8B-q4_k_m.gguf」と入力し「Download」ボタンを押下する。<a class="headerlink" href="#2-file-name-for-gguf-modelsllama-3-elyza-jp-8b-q4_k_mggufdownload" title="Permanent link">&para;</a></h3>
<ul>
<li>ダウンロードできない場合は手順①で表示されたリストからコピペする。</li>
</ul>
<h3 id="3-model-llama-3-elyza-jp-8b-q4_k_mggufloadsave-settings">③ 画面左上の「Model」選択プルダウン右の更新(ぐるぐる矢印)ボタンを押下し、 プルダウンから「Llama-3-ELYZA-JP-8B-q4_k_m.gguf」を選択した状態で「Load」ボタンと「Save settings」ボタンを押下する。<a class="headerlink" href="#3-model-llama-3-elyza-jp-8b-q4_k_mggufloadsave-settings" title="Permanent link">&para;</a></h3>
<ul>
<li>プルダウンに「Llama-3-ELYZA-JP-8B-q4_k_m.gguf」が表示されない場合、WebUIを一度再起動する。</li>
</ul>
<hr />
<h2 id="_2">動作確認<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<h3 id="chatsend-a-messagegenerate">「Chat」タブを開き、画面下の「Send a message」と書かれたテキストボックスに質問などを入力し「Generate」ボタンを押下する。<a class="headerlink" href="#chatsend-a-messagegenerate" title="Permanent link">&para;</a></h3>
<h4 id="8b1">8Bモデル（レスポンス：1分ぐらい）<a class="headerlink" href="#8b1" title="Permanent link">&para;</a></h4>
<ul>
<li>ChatGPTについて説明してください。<ul>
<li>ChatGPTは、Meta AIが開発した大規模言語モデルです。ChatGPTは、膨大な量のテキストデータを学習し、自然言語処理(NLP)技術を適用することで、人間のような会話が可能なAIです。</li>
<li>ChatGPTの特徴は以下の通りです。</li>
<li>自然言語理解(NLU): ChatGPTは、ユーザーの入力された文を理解することができます。具体的には、文章の意味や文脈を把握し、内容を解釈することが可能です。</li>
<li>自然言語生成(NLG): ChatGPTは、与えられた入力文を元に、文章や文を生成することができます。ChatGPTは、ユーザーの要望や目的に応じて、適切な文や文章を生成することができます。</li>
<li>その他の機能: ChatGPTには、会話や文章を管理するための多くの機能があります。例えば、ユーザーとAIの会話を追跡し、会話の内容や文脈を把握することができます。</li>
<li>ChatGPTは、多くの分野で応用が期待されます。例えば、顧客サポートや、教育、研究、コミュニケーションなどです。</li>
<li>ChatGPTは、AIが人間の会話を模倣する能力を高めるために非常に有用です。AIがより人間に近い会話を可能にすることで、人とAIの相互作用がより自然になることが期待されます。</li>
</ul>
</li>
</ul>
<!-- -->

<ul>
<li>ISMS説明会に参加した社員に対して、「本日はお忙しい中、お時間をいただき」ではじまるメールを書いてください。</li>
</ul>
<pre><code>件名: ISMS説明会のご参加ありがとうございました

本日はお忙しい中、ISMS説明会にご参加いただきありがとうございました。

情報セキュリティマネジメントシステム(ISMS)の概要や、弊社のISMSの取組みについて理解を深めていただく機会となりました。

今回の説明会で学んだことを、日常業務や内部監査に活かして、情報セキュリティの向上にご尽力いただければと思います。

資料の送付や、ご質問いただいた点の回答については、後日改めてご連絡いたします。

今後とも、弊社の情報セキュリティ対策にご協力いただけますようよろしくお願い申し上げます。
</code></pre>
<hr />
<h2 id="_3">参考サイト<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="https://zenn.dev/headwaters/articles/78705a730b297d">Llama-3-ELYZA-JP-8Bを動かす</a></li>
<li><a href="https://recruit.gmo.jp/engineer/jisedai/blog/local-autopilot-with-continue/">ローカル環境でコード生成を使いたい 〜Continue+Llama.cpp+ELYZA-japanese-CodeLlamaを試してみた〜</a></li>
<li><a href="https://weel.co.jp/media/innovator/llama-3-elyza-jp/">【Llama-3-ELYZA-JP】日本語性能でトップクラス！GPT-4やClaude 3 Sonnetを超えるLLM登場 | WEEL</a></li>
<li><a href="https://prtimes.jp/main/html/rd/p/000000046.000047565.html">ELYZA、「GPT-4」を上回る性能の日本語LLMを開発・公開</a></li>
<li><a href="https://weel.co.jp/media/tech/elyza-japanese-codellama-7b/">【ELYZA japanese CodeLlama 7b】日本語版CodeLlamaの性能をGPT-4と徹底比較してみた | WEEL</a></li>
</ul>
<p><br></p>
<style>
font-family: 'Note Sans JP','Hiragino Kaku Gothic Pro', 'ヒラギノ角ゴ Pro W3, Meiryo', メイリオ, Arial, sans-serif;
table {border-left:1px solid #333;}
th {background:#eee;color:#000 !important;border-top:1px solid #333;}
td {background:#fff;color:#333;border-bottom:1px solid #333;}
th,td {border-left:dotted 1px #333;}
th:first-of-type {border-left:1px solid #333;}
td:first-of-type {border-left:1px solid #333;}
th:last-of-type {border-right:1px solid #333;}
td:last-of-type {border-right:1px solid #333;}
hr {border-bottom:1px dashed #999;}
</style>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../phi-3-mini/" class="btn btn-neutral float-left" title="Phi-3-mini導入"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../stable-diffusion/" class="btn btn-neutral float-right" title="Stable-Diffusion導入">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
      <p>Copyright © 2023-2024 kumanekokk.com</p>
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../phi-3-mini/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../stable-diffusion/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="../js/common.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
